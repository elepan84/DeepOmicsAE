{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97c4dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "RANDOM_STATE = 55 ## We will pass it to every sklearn call so we ensure reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cafd0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This function performs feature selection from a given DataFrame.\n",
    "#     The function uses the SelectKBest method from the sklearn library to select\n",
    "#     the 'k_feat' best features based on the f_classif score.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (DataFrame): The input DataFrame. \n",
    "#     k_feat (int): The number of top features to select.\n",
    "#     cols_X (list): The column indices for the features (X).\n",
    "#     y_label (string): The column name for the target variable (y).\n",
    "\n",
    "#     Returns:\n",
    "#     X_new (array): The values of the selected features.\n",
    "#     df_selected (DataFrame): DataFrame of the selected features, preserving original indices.\n",
    "    \n",
    "\n",
    "def feature_selection(df, k_feat, cols_X, y_label):   \n",
    "    X = df.iloc[:, cols_X]\n",
    "    y = df[y_label]\n",
    "    #import pdb; pdb.set_trace()\n",
    "    # feature selection\n",
    "    selector = SelectKBest(f_classif, k=k_feat)  \n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    # Get the selected features and their indices\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_columns = X.columns[selected_indices]\n",
    "\n",
    "    # Create df_selected with selected features and preserved index values\n",
    "    df_selected = pd.DataFrame(X_new, columns=selected_columns, index=df.index)\n",
    "    return(X_new, df_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97fae93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_encoder(n_feat, n2, n3, latent):\n",
    "    ### This function constructs the encoder part of the autoencoder model. \n",
    "    ### It takes as input the number of features, and the number of neurons for the three layers.\n",
    "    # The model architecture consists of two hidden layers followed by a latent space representation.\n",
    "\n",
    "    # Parameters:\n",
    "    # n_feat (int): The number of features in the input data.\n",
    "    # n2 (int): The number of neurons in the first hidden layer.\n",
    "    # n3 (int): The number of neurons in the second hidden layer.\n",
    "    # latent (int): The number of neurons in the latent space representation.\n",
    "\n",
    "    # Returns:\n",
    "    # keras.Model: The constructed encoder model.\n",
    "    \n",
    "    inputs = keras.Input(shape=(n_feat,))\n",
    "    x = layers.Dense(n2, activation='relu')(inputs)\n",
    "    x = layers.Dense(n3, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent)(x)\n",
    "    z_log_var = layers.Dense(latent)(x)\n",
    "    return keras.Model(inputs, [z_mean, z_log_var], name='encoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76b82c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder\n",
    "def make_decoder(n_feat, n2, n3, latent):\n",
    "    ### This function constructs the decoder part of the autoencoder model. \n",
    "    ### It takes as input the number of features, and the number of neurons for the three layers.\n",
    "    # The model architecture consists of two hidden layers followed by an output layer with\n",
    "    # the same size as the input data.\n",
    "\n",
    "    # Parameters:\n",
    "    # n_feat (int): The number of features in the input data.\n",
    "    # n2 (int): The number of neurons in the first hidden layer.\n",
    "    # n3 (int): The number of neurons in the second hidden layer.\n",
    "    # latent (int): The number of neurons in the latent space representation.\n",
    "\n",
    "    # Returns:\n",
    "    # keras.Model: The constructed decoder model.\n",
    "        \n",
    "    latent_inputs = keras.Input(shape=(latent,))\n",
    "    x = layers.Dense(n3, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(n2, activation='relu')(x)\n",
    "    outputs = layers.Dense(n_feat)(x)\n",
    "    return keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e0bbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling layer\n",
    "def create_sampling_layer():\n",
    "    ### This function creates and returns an instance of a custom Sampling layer. \n",
    "    ### This layer uses (z_mean, z_log_var) to sample a point 'z' from the latent distribution.\n",
    "\n",
    "    # Returns:\n",
    "    # Sampling: An instance of the custom Sampling layer.\n",
    "\n",
    "    class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z\"\"\"\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = tf.shape(z_mean)[0]\n",
    "            dim = tf.shape(z_mean)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    return Sampling() # <-- returns an instance of the Sampling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ff50c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full AE model by combining the encoder, decoder, and sampling layers\n",
    "def ae_model(n_feat, n2, n3, latent):\n",
    "    ### This function creates the full autoencoder model by combining the encoder, decoder, \n",
    "    ### and sampling layers. It takes as input the number of features, and the number of neurons \n",
    "    ### for the three layers.\n",
    "    inputs = keras.Input(shape=(n_feat,))\n",
    "    encoder = make_encoder(n_feat, n2, n3, latent)\n",
    "    decoder = make_decoder(n_feat, n2, n3, latent)\n",
    "    #sampling = Sampling()\n",
    "    sampling = create_sampling_layer()\n",
    "    z_mean, z_log_var = encoder(inputs)\n",
    "    z = sampling([z_mean, z_log_var])\n",
    "    outputs = decoder(z)\n",
    "    ae = keras.Model(inputs, outputs, name='ae')\n",
    "    return(ae, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54a3554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run it first with n_epochs set to 300, then use min_val_loss_epochs for the final run\n",
    "## verbose can be either set to 1 to visualize the losses as the model runs, or 0 to silence them\n",
    "def ae_model_run(ae, X, X_train, X_val, n_epochs, verbose, encoder):\n",
    "    ### This function compiles and trains the autoencoder model, then applies it to the input data X.\n",
    "    ### It also calculates and returns the validation loss history and the minimum validation loss epoch.\n",
    "\n",
    "    # Parameters:\n",
    "    # ae (keras.Model): The autoencoder model to train and apply to the data.\n",
    "    # X (DataFrame): The input data on which the model will be applied after training.\n",
    "    # X_train (DataFrame): The training data.\n",
    "    # X_val (DataFrame): The validation data used during training.\n",
    "    # n_epochs (int): The number of epochs to train the model.\n",
    "    # verbose (int): Determines whether to display loss information during training (1 = yes, 0 = no).\n",
    "    # encoder (keras.Model): The encoder part of the autoencoder model.\n",
    "\n",
    "    # Returns:\n",
    "    # history (History): The training history, including loss and validation loss values at each epoch.\n",
    "    # val_loss (list): A list of validation loss values at each epoch.\n",
    "    # min_val_loss_epoch (int): The epoch at which the minimum validation loss was achieved.\n",
    "    # bottleneck_features (ndarray): The encoded features produced by applying the trained encoder to the input data.\n",
    "    \n",
    "    ae.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "    history = ae.fit(X_train, X_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_val, X_val), verbose=verbose)\n",
    "\n",
    "    encoder_output = encoder.predict(X)\n",
    "    bottleneck_features = encoder_output[0]\n",
    "    val_loss = history.history['val_loss']\n",
    "    min_val_loss = min(val_loss)\n",
    "    min_val_loss_epoch = val_loss.index(min_val_loss) + 1\n",
    "    return (history, val_loss, min_val_loss_epoch, bottleneck_features, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f392771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model_setup_and_run(n_feat, n2, n3, latent, X, X_train, X_val, n_epochs, verbose):\n",
    "    # This function sets up the autoencoder model, trains it, applies it to the data, and returns various outputs.\n",
    "\n",
    "    # Parameters:\n",
    "    # n_feat (int): The number of features in the input data.\n",
    "    # n2 (int): The number of neurons in the first hidden layer.\n",
    "    # n3 (int): The number of neurons in the second hidden layer.\n",
    "    # latent (int): The number of neurons in the latent space representation.\n",
    "    # X (DataFrame): The input data on which the model will be applied after training.\n",
    "    # X_train (DataFrame): The training data.\n",
    "    # X_val (DataFrame): The validation data used during training.\n",
    "    # n_epochs (int): The number of epochs to train the model.\n",
    "    # verbose (int): Determines whether to display loss information during training (1 = yes, 0 = no).\n",
    "\n",
    "    # Returns:\n",
    "    # history (History): The training history, including loss and validation loss values at each epoch.\n",
    "    # val_loss (list): A list of validation loss values at each epoch.\n",
    "    # min_val_loss_epoch (int): The epoch at which the minimum validation loss was achieved.\n",
    "    # bottleneck_features (ndarray): The encoded features produced by applying the trained encoder to \n",
    "    # the input data.\n",
    "    \n",
    "    ae, encoder = ae_model(n_feat, n2, n3, latent)\n",
    "    history, val_loss, min_val_loss_epoch, bottleneck_features,encoder = ae_model_run(ae, X, X_train, X_val, n_epochs, verbose, encoder)\n",
    "    if min_val_loss_epoch < 20: min_val_loss_epoch = 20\n",
    "    return history, val_loss, min_val_loss_epoch, bottleneck_features, encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cfc19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(df, cols_X_prot, cols_X_met, n_comb):\n",
    "    # Define the parameter values\n",
    "    no_samples = df.shape[0]\n",
    "    prot_cols = cols_X_prot.stop - cols_X_prot.start\n",
    "    met_cols = cols_X_met.stop - cols_X_met.start\n",
    "    \n",
    "    # Define the parameter values\n",
    "    min_val = 50\n",
    "    max_val_prot = round(prot_cols * 0.35)\n",
    "    max_val_met = round(met_cols * 0.35)\n",
    "    latent_min = round(no_samples * 0.01)\n",
    "    if latent_min == 1 or latent_min == 2: latent_min = 3\n",
    "    latent_max = round(no_samples * 0.025) + 1\n",
    "    if latent_max == 1 or latent_max == 2: latent_max = 3\n",
    "    latent_n = latent_max - latent_min\n",
    "    if latent_n == 0: latent_n = 1\n",
    "    kprot_values = sorted(random.sample(range(min_val, max_val_prot), 150))  # Randomly select 150 values from the range\n",
    "    kmet_values = sorted(random.sample(range(min_val, max_val_met), 75))  # Randomly select 75 values from the range\n",
    "    latent_values = random.sample(range(latent_min, latent_max), latent_n)  # Randomly select latent_n values from the range\n",
    "    \n",
    "    # Define the percentiles to select\n",
    "    percentiles1 = [0, 2.5, 5, 7.5, 10]\n",
    "    percentiles2 = [0, 4.5, 9, 13.5, 18]\n",
    "    # Define the range values\n",
    "    range_prot = max_val_prot - min_val\n",
    "    range_met = max_val_met - min_val\n",
    "\n",
    "    # Select values at these percentiles for kprot and kmet\n",
    "    selected_kprot_values_bottom = [round(min_val + np.percentile(range(range_prot), percentile)) for percentile in percentiles1]\n",
    "    selected_kmet_values_bottom = [round(min_val + np.percentile(range(range_met), percentile)) for percentile in percentiles2]\n",
    "\n",
    "    # Select values at these percentiles for kprot and kmet\n",
    "    selected_kprot_values_top = [round(min_val + np.percentile(range(range_prot), 100 - percentile)) for percentile in percentiles1]\n",
    "    selected_kmet_values_top = [round(min_val + np.percentile(range(range_met), 100 - percentile)) for percentile in percentiles2]    \n",
    "    \n",
    "    # Shuffle the kprot and kmet lists\n",
    "    random.shuffle(selected_kprot_values_bottom)\n",
    "    random.shuffle(selected_kmet_values_bottom)\n",
    "    random.shuffle(selected_kprot_values_top)\n",
    "    random.shuffle(selected_kmet_values_top)\n",
    "\n",
    "    # Select one element from each list to form a combination\n",
    "    selected_bottom_combinations = [(kprot, kmet, random.choice(latent_values)) for kprot, kmet in zip(selected_kprot_values_bottom[:5], selected_kmet_values_bottom[:5])]\n",
    "    selected_top_combinations = [(kprot, kmet, random.choice(latent_values)) for kprot, kmet in zip(selected_kprot_values_top[:5], selected_kmet_values_top[:5])]\n",
    "\n",
    "    # Generate all parameter combinations\n",
    "    all_combinations = []\n",
    "    for kprot in kprot_values:\n",
    "        for kmet in kmet_values:\n",
    "            for latent in latent_values:\n",
    "                all_combinations.append((kprot, kmet, latent))\n",
    "\n",
    "    # Subtract the selected combinations from all combinations\n",
    "    remaining_combinations = [comb for comb in all_combinations if comb not in selected_bottom_combinations and comb not in selected_top_combinations]\n",
    "\n",
    "    # Randomly select from the remaining combinations\n",
    "    random.shuffle(remaining_combinations)\n",
    "    selected_random_combinations = remaining_combinations[:(n_comb - 10)]  # Exclude 10 combinations that were selected based on percentiles\n",
    "\n",
    "    # Combine the selected combinations\n",
    "    selected_combinations = selected_bottom_combinations + selected_top_combinations + selected_random_combinations\n",
    "    return(selected_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e53a76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimization(df, n_all_feat, n_comb, cols_X_prot, \n",
    "                       cols_X_met, cols_clin, cols_X_expr, y_label):\n",
    "    \n",
    "    # This function performs model optimization by randomly sampling possible combinations of parameters \n",
    "    # and running feature selection, model training, and evaluation for each combination.\n",
    "\n",
    "    # Parameters:\n",
    "    # df: The input DataFrame containing the features and target variable\n",
    "    # n_all_feat: Total number of features in the dataframe\n",
    "    # n_comb: Number of combinations of parameters to test\n",
    "    # cols_X_prot: Columns in the dataframe that represent proteomics data\n",
    "    # cols_X_met: Columns in the dataframe that represent metabolomics data\n",
    "    # cols_clin: Columns in the dataframe that represent clinical data\n",
    "    # cols_X_expr: Columns in the dataframe that represent the input features for PCA\n",
    "    # y_label: The column in the dataframe that represents the target variable\n",
    "\n",
    "    # Returns:\n",
    "    # df_results: A DataFrame containing the results of the model optimization\n",
    "    # df_selected: The final selected features in a DataFrame\n",
    "\n",
    "    \n",
    "    # Initialize an empty DataFrame with columns\n",
    "    columns = ['kprot', 'kmet', 'latent', 'sil_score_initial',\n",
    "              'sil_score_final', 'pca_all', 'pca_extracted']\n",
    "\n",
    "    df_results = pd.DataFrame(columns=columns)\n",
    "    selected_combinations = combinations(df, cols_X_prot,cols_X_met, n_comb)\n",
    "\n",
    "    # Perform PCA\n",
    "    X = df.iloc[:, cols_X_expr]\n",
    "    y = df[y_label]\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    silhouette_feat = silhouette_score(X, y)\n",
    "    \n",
    "    # Calculate Silhouette Scores\n",
    "    pca_silhouette_score_all_feat = silhouette_score(X_pca, y)\n",
    "    \n",
    "    i = 0\n",
    "    # Loop over each combination\n",
    "    for kprot, kmet, latent in selected_combinations:\n",
    "        i = i +1\n",
    "        print(i)\n",
    "        # Select features\n",
    "        print(\"Selecting features\")\n",
    "        X_new_prot, df_selected_prot = feature_selection(df, kprot, cols_X_prot, y_label)\n",
    "        X_new_met, df_selected_met = feature_selection(df, kmet, cols_X_met, y_label)\n",
    "        df_selected = pd.concat([df_selected_prot, \n",
    "                                 df_selected_met, df.iloc[:, cols_clin], df[y_label]], axis=1)\n",
    "\n",
    "        # Define the autoencoder model architecture\n",
    "        n_feat = df_selected.iloc[:, :-1].shape[1]\n",
    "        n2 = round(n_feat/1.5)\n",
    "        if (n2 <= 70):\n",
    "            n3 = round(n2/2)\n",
    "        if (n2 > 70) and (n2 <= 200):\n",
    "            n3 = round(n2/5)\n",
    "        else:\n",
    "            n3 = round(n2/6)\n",
    "        \n",
    "        # Separate features and labels\n",
    "        X = df_selected.iloc[:, :-1]\n",
    "        y = df_selected.iloc[:, -1]\n",
    "\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                          test_size=0.2, random_state=42)\n",
    "\n",
    "        print(\"Extracting features\")\n",
    "        ### run the autoencoder first with n_epochs set to 300, then use min_val_loss_epochs for the final run\n",
    "        ## verbose can be either set to 1 to visualize the losses as the model runs, or 0 to silence them\n",
    "\n",
    "        history, val_loss, min_val_loss_epoch, bottleneck_features, encoder = ae_model_setup_and_run(n_feat, n2, n3, latent, X, X_train, X_val, 300, verbose = 0)\n",
    "        history, val_loss, min_val_loss_epoch, bottleneck_features, encoder = ae_model_setup_and_run(n_feat, n2, n3, latent, X, X_train, X_val, min_val_loss_epoch, verbose = 0)                                                                                       \n",
    "\n",
    "        # Create a pandas DataFrame for the extracted bottleneck features\n",
    "        extracted_features_df = pd.DataFrame(bottleneck_features, columns=[f\"Feature_{i}\" for i in range(latent)])\n",
    "        extracted_features_df[y_label] = y\n",
    "\n",
    "        ##### perform PCA and tSNE again after selecting features\n",
    "\n",
    "        # Separate features and labels\n",
    "        X = bottleneck_features\n",
    "\n",
    "        # Perform PCA and t-SNE\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "\n",
    "        # Calculate Silhouette Scores\n",
    "        pca_silhouette_score_extracted_feat = silhouette_score(X_pca, y)\n",
    "        silhouette_bottleneck = silhouette_score(bottleneck_features, y)\n",
    "\n",
    "\n",
    "        data = {\n",
    "        'kprot': [kprot],\n",
    "        'kmet': [kmet],\n",
    "        'latent': [latent],\n",
    "        'sil_score_initial': [silhouette_feat],\n",
    "        'sil_score_final': [silhouette_bottleneck],\n",
    "        'pca_all': [pca_silhouette_score_all_feat],\n",
    "        'pca_extracted': [pca_silhouette_score_extracted_feat],\n",
    "        }\n",
    "\n",
    "        new_row = pd.DataFrame(data)\n",
    "\n",
    "        ## Add the results to the results DataFrame\n",
    "        df_results = pd.concat([df_results, new_row], ignore_index=True)\n",
    "        \n",
    "    return(df_results, df_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_xgboost_env",
   "language": "python",
   "name": "tensorflow_xgboost_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
